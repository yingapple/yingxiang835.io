---
title: "在LLM时代里更好的进行系统迭代"
layout: post
date: 2023-07-26 00:00
# image: /assets/images/markdown.jpg
headerImage: false
tag:
- LLM
- Iteration framework
category: blog
author: Xiang Ying
description: 在无法训练大模型本身的时候，我们依然应该以数据化的视角迭代系统，去顺其自然的增强产品的壁垒
---

在大型语言模型（Large Language Model，简称LLM）的时代，我们可以将与此技术紧密相关的组织划分为以下三个主要类别：

1. **底层通用大模型研发组织**：这类组织专注于构建和优化底层的通用大模型，为上层应用提供基础和支持。

2. **开源模型业务迁移组织**：这些组织主要工作是将开源的大模型应用并迁移到具体的业务场景中，实现模型与实际应用的结合。

3. **平台型和应用型工作组织**：基于底层通用大模型，这类组织负责完成各种平台型和应用型的开发工作，将模型的能力具体化和个性化，以满足更具体的业务需求。


对于前两类组织，我们可以比较容易地理解他们的运作方式。他们在系统迭代的过程中，与已经集成了深度学习模型的传统系统保持一致。底层通用大模型的研发通常由大型公司和顶尖的创业公司担当，而将开源模型迁移到具体业务的任务，则通常由一些在原有业务基础上寻求“技术升级”的技术公司承接，至少表面上是这样的情况。

然而，对于第三类组织（也就是我目前所在的组织，已经从第二类切换为了这一类），作为真正由大型模型推动的新型系统，我们可能并不具备对底层通用大模型进行微调（fine-tune）的能力（或者说，这样做的成本太高）。在这种情况下，如何进行系统性的迭代升级，不仅关乎解决特性开发本身，更是面向企业自身价值积累和竞争壁垒构建的至关重要的一环。因此，我认为对于这最后一类组织，我们需要清楚地认识到以下几点：

1. **Prompt不是壁垒**：即模型的输入语句（Prompt），并不能构成持久的竞争优势或者说壁垒。

2. **系统架构和复杂的工程设计只是短期优势**：虽然它们可能在短期内提供了竞争优势，但这些并不能形成长期持久的壁垒。


在我看来，组织的真正壁垒有两个。首先，持续的技术突破和创新速度，这主要源于成长型思维。然而，对于这种持续性，我保持一定的怀疑，因为它需要非常优秀、独立且思路清晰的领导者和相关团队。在不那么优秀的领导者的引领下，组织容易陷入焦虑和过度加班的困扰。其次，通过数据积累、用户习惯形成的壁垒。这种壁垒更加稳固，构建过程往往水到渠成，更加自然。

让我们回到本文的主题，结合第二种壁垒的构建，尽管无法调整底层的大模型，但我们也应该建立一种数据化的方案进行迭代。这个过程主要分为2个步骤：

## 定义核心指标和模块指标

在构建系统时，我们首先需要定义核心指标和模块指标。这些指标是系统迭代的基础，应满足以下几个条件：

- **可观测**：这一点非常基础，也非常重要。对于基于LLM构建的系统，许多直接指标在初期可能并没有完美的评估方法，如是否真正满足了用户的灵活需求等。因此，一般建议使用业务指标，比如在对话系统中就是对话轮数。

- **反映技术本身的特性**：LLM的特性应该是灵活性和通用性。在短期内，LLM及基于LLM搭建的中间层平台并不会具备独立解决深度问题的能力，更多的是作为人的增效工具，大幅提升效率。因此，指标应考虑到AI是与人相互协作的。

- **反映对用户的价值和产品的真实目标**：对于LLM来说，存在许多的评估数据集，这些数据集可以从多维度衡量LLM的能力。但对于基于LLM实现的系统来说，一定是有与LLM本身不一样的目标能力的。因此，这些基础能力的评估是不足的。我们应明确产品本身的目标是什么，并相应地设定数据埋点。

- **核心指标数量要少，甚至一个就好**：多目标同时优化固然是最好的，但在现实情况下往往是顾此失彼的状态。那么，在多目标的情况下就会导致无法判断好坏，难以评定系统是升级了还是降级了。

## 建立体系

为了成功实现数据驱动，我们需要建立一个完整且健壮的数据体系。具体来说，这个体系应包括数据埋点、指标统计和在线监控以及新模块的A/B测试：

- **数据埋点**：首先，我们需要在关键的用户交互点设置数据埋点，以收集用户行为数据。数据埋点不仅可以帮助我们了解用户在使用我们的产品时的行为模式，还可以帮助我们发现可能存在的问题。为了更有效地进行数据埋点，我们需要明确哪些用户行为是关键的，应该被跟踪和记录。此外，我们还需要确保数据的质量和完整性。

- **指标统计和在线监控**：有了数据，我们接下来需要将这些数据转化为有意义的信息。这就需要我们进行指标统计和在线监控。指标统计可以帮助我们了解产品的性能，比如用户活跃度、留存率、转化率等。在线监控则可以让我们实时地了解产品的运行状态，及时发现和解决问题。为了做好指标统计和在线监控，我们需要选择适合的工具，并且明确我们关心的指标是什么。

- **新模块的A/B测试**：在迭代过程中，我们经常会引入新的特性或模块。为了评估这些新特性或模块对产品性能的影响，我们需要进行A/B测试。A/B测试可以让我们对比新旧版本的产品性能，从而做出基于数据的决策。在进行A/B测试时，我们需要确保测试的公正性，比如控制变量、确保用户的随机分配等。

搜推广系统在这方面的工作已经做得非常好，其数据体系不仅健全而且成熟，可以支持他们做出快速且准确的决策，我们可以学习和借鉴。


作为技术管理者，我们不仅需要建立健壮的数据体系，还需要建立一套有效的运转机制。这一机制的目标是让每一位团队成员都能够顺畅地进入到这个数据驱动的迭代循环中，从而提高工作效率，提升团队整体的生产力。

在新兴的系统中，有机会**重新定义核心指标**和**构建迭代体系**。这对于当前这波技术人来说是一项挑战，也是一次机遇。这不仅让我们有机会从零开始，更好地理解和掌握“算法”的本质含义：在用户交互中沉淀数据，在数据中发现价值，然后回到用户交互中验证，而不仅仅是训练模型。这也为我们提供了一个平台，去发掘并实践新的思考方式和方法，为我们的产品和服务创造更大的价值。

